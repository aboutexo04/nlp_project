"""
train_bart_r3f.py - ëŒ€í™” ìš”ì•½ íŠ¹í™” ëª¨ë¸
"""
import torch
from transformers import (
    BartForConditionalGeneration,
    PreTrainedTokenizerFast,
    Seq2SeqTrainer,
    Seq2SeqTrainingArguments,
    DataCollatorForSeq2Seq,
    EarlyStoppingCallback,
    TrainerCallback
)
from datasets import Dataset
import os
import warnings
import numpy as np
from rouge_score import rouge_scorer
from datetime import datetime
import sys
import logging

warnings.filterwarnings('ignore')

# ===== ì„¤ì • =====
EXPERIMENT_NAME = "bart_r3f"  # âœ… ì‹¤í—˜ ì´ë¦„
NUM_EPOCHS = 5
BATCH_SIZE = 16
LEARNING_RATE = 5e-5
MAX_INPUT_LENGTH = 512
MAX_TARGET_LENGTH = 128
EARLY_STOPPING_PATIENCE = 3

# ì‹¤í—˜ë³„ í´ë” êµ¬ì¡°
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
EXPERIMENT_DIR = f"./outputs/{EXPERIMENT_NAME}_{timestamp}"
OUTPUT_DIR = f"{EXPERIMENT_DIR}/checkpoints"
FINAL_MODEL_DIR = f"{EXPERIMENT_DIR}/models"
LOG_DIR = f"{EXPERIMENT_DIR}/logs"

os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(FINAL_MODEL_DIR, exist_ok=True)
os.makedirs(LOG_DIR, exist_ok=True)

# ===== ë¡œê¹… ì„¤ì • =====
log_file = f"{LOG_DIR}/training.log"

logger = logging.getLogger()
logger.setLevel(logging.INFO)

file_handler = logging.FileHandler(log_file, mode='w', encoding='utf-8')
file_handler.setLevel(logging.INFO)
file_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
file_handler.setFormatter(file_formatter)

console_handler = logging.StreamHandler(sys.stdout)
console_handler.setLevel(logging.INFO)
console_formatter = logging.Formatter('%(message)s')
console_handler.setFormatter(console_formatter)

logger.addHandler(file_handler)
logger.addHandler(console_handler)

logger.info("="*70)
logger.info("BART-R3F Fine-tuning - ëŒ€í™” ìš”ì•½ íŠ¹í™”")
logger.info("="*70)
logger.info(f"ì‹¤í—˜ ì´ë¦„: {EXPERIMENT_NAME}")
logger.info(f"ì‹¤í—˜ ë””ë ‰í† ë¦¬: {EXPERIMENT_DIR}")
logger.info("="*70)

# ===== ë””ë°”ì´ìŠ¤ ì„¤ì • =====
def setup_device():
    if torch.cuda.is_available():
        device = torch.device("cuda")
        device_name = "CUDA GPU"
    elif torch.backends.mps.is_available():
        device = torch.device("mps")
        device_name = "MPS (Apple Silicon GPU)"
    else:
        device = torch.device("cpu")
        device_name = "CPU"

    logger.info(f"\nâœ“ ë””ë°”ì´ìŠ¤: {device_name}")
    return device

device = setup_device()

# ===== ë°ì´í„° ë¡œë“œ =====
print("\n" + "="*70)
print("ë°ì´í„° ë¡œë“œ")
print("="*70)

from src.data_loader import load_json_data
from src.postprocessing import fix_summary_punctuation_and_format

train_data = load_json_data('./data/sample/train_sample/')
val_data = load_json_data('./data/sample/val_sample/')

print(f"Train: {len(train_data):,}ê°œ")
print(f"Validation: {len(val_data):,}ê°œ")

# ===== ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ =====
print("\n" + "="*70)
print("ëª¨ë¸ ë¡œë“œ")
print("="*70)

model_name = "alaggung/bart-r3f"  # âœ… ëŒ€í™” ìš”ì•½ íŠ¹í™”!
print(f"ëª¨ë¸: {model_name}")

try:
    tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)
    model = BartForConditionalGeneration.from_pretrained(model_name)
    print(f"âœ“ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
except Exception as e:
    print(f"âš ï¸ ì˜¤ë¥˜: {e}")
    print("ëŒ€ì²´ í† í¬ë‚˜ì´ì € ì‹œë„...")
    from transformers import BartTokenizer
    tokenizer = BartTokenizer.from_pretrained(model_name)
    model = BartForConditionalGeneration.from_pretrained(model_name)
    print(f"âœ“ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (BartTokenizer)")

model = model.to(device)
print(f"ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in model.parameters()):,}")

# ===== í† í¬ë‚˜ì´ì§• í•¨ìˆ˜ =====
def preprocess_function(examples):
    inputs = tokenizer(
        examples['dialogue'],
        max_length=MAX_INPUT_LENGTH,
        truncation=True,
        padding='max_length'
    )

    with tokenizer.as_target_tokenizer():
        labels = tokenizer(
            examples['summary'],
            max_length=MAX_TARGET_LENGTH,
            truncation=True,
            padding='max_length'
        )

    inputs['labels'] = labels['input_ids']
    return inputs

# ===== ROUGE í‰ê°€ í•¨ìˆ˜ =====
def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)
    
    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)
    
    decoded_preds = [fix_summary_punctuation_and_format(pred) for pred in decoded_preds]
    
    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=False)
    
    rouge1_scores = []
    rouge2_scores = []
    rougeL_scores = []
    
    for pred, label in zip(decoded_preds, decoded_labels):
        scores = scorer.score(label, pred)
        rouge1_scores.append(scores['rouge1'].fmeasure)
        rouge2_scores.append(scores['rouge2'].fmeasure)
        rougeL_scores.append(scores['rougeL'].fmeasure)
    
    rouge1_avg = np.mean(rouge1_scores)
    rouge2_avg = np.mean(rouge2_scores)
    rougeL_avg = np.mean(rougeL_scores)
    final_score = rouge1_avg + rouge2_avg + rougeL_avg
    
    return {
        'rouge1': rouge1_avg,
        'rouge2': rouge2_avg,
        'rougeL': rougeL_avg,
        'rouge_score': final_score
    }

# ===== Dataset ë³€í™˜ =====
print("\n" + "="*70)
print("ë°ì´í„°ì…‹ í† í¬ë‚˜ì´ì§•")
print("="*70)

train_dataset = Dataset.from_pandas(train_data.reset_index(drop=True))
val_dataset = Dataset.from_pandas(val_data.reset_index(drop=True))

train_tokenized = train_dataset.map(
    preprocess_function,
    batched=True,
    remove_columns=train_dataset.column_names,
    desc="Train"
)

val_tokenized = val_dataset.map(
    preprocess_function,
    batched=True,
    remove_columns=val_dataset.column_names,
    desc="Validation"
)

print(f"âœ“ í† í¬ë‚˜ì´ì§• ì™„ë£Œ")

# ===== Training Arguments =====
training_args = Seq2SeqTrainingArguments(
    output_dir=OUTPUT_DIR,
    num_train_epochs=NUM_EPOCHS,
    per_device_train_batch_size=BATCH_SIZE,
    per_device_eval_batch_size=BATCH_SIZE,
    learning_rate=LEARNING_RATE,
    warmup_steps=100,
    weight_decay=0.01,
    logging_dir=LOG_DIR,
    logging_steps=50,
    eval_strategy="epoch",
    save_strategy="epoch",
    save_total_limit=2,
    load_best_model_at_end=True,
    metric_for_best_model="rouge_score",
    greater_is_better=True,
    predict_with_generate=True,
    generation_max_length=120,
    generation_num_beams=5,
    gradient_accumulation_steps=2,
    report_to="none",
    disable_tqdm=False,
    fp16=torch.cuda.is_available()
)

# ===== Data Collator =====
data_collator = DataCollatorForSeq2Seq(
    tokenizer=tokenizer,
    model=model,
    padding=True
)

# ===== Callback =====
class RoundedLoggingCallback(TrainerCallback):
    def on_log(self, args, state, control, logs=None, **kwargs):
        if logs is not None:
            for key, value in logs.items():
                if isinstance(value, float):
                    logs[key] = round(value, 4)

# ===== Trainer =====
trainer = Seq2SeqTrainer(
    model=model,
    args=training_args,
    train_dataset=train_tokenized,
    eval_dataset=val_tokenized,
    data_collator=data_collator,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
    callbacks=[
        EarlyStoppingCallback(early_stopping_patience=EARLY_STOPPING_PATIENCE),
        RoundedLoggingCallback()
    ]
)

# ===== Fine-tuning =====
print("\n" + "="*70)
print("Fine-tuning ì‹œì‘!")
print("="*70)

try:
    trainer.train()
    print("\nâœ“ Fine-tuning ì™„ë£Œ!")
except Exception as e:
    print(f"\nâš ï¸ Training ì¤‘ ì˜¤ë¥˜: {e}")
    raise

# ===== í‰ê°€ =====
eval_results = trainer.evaluate()
print(f"\nìµœì¢… ROUGE Score: {eval_results['eval_rouge_score']:.4f}")

# ===== ëª¨ë¸ ì €ì¥ =====
trainer.save_model(FINAL_MODEL_DIR)
tokenizer.save_pretrained(FINAL_MODEL_DIR)
print(f"âœ“ ëª¨ë¸ ì €ì¥: {FINAL_MODEL_DIR}")

# ===== ë¹„êµ =====
print("\n" + "="*70)
print("ë¹„êµ")
print("="*70)
print(f"kobart-summarization: 0.2423")
print(f"bart-r3f (í˜„ì¬):      {eval_results['eval_rouge_score']:.4f}")
print(f"ì°¨ì´:                 {eval_results['eval_rouge_score'] - 0.2423:+.4f}")

if eval_results['eval_rouge_score'] > 0.2423:
    print("\nğŸ‰ bart-r3fê°€ ë” ì¢‹ìŠµë‹ˆë‹¤!")
else:
    print("\nâš ï¸ kobart-summarizationì´ ë” ì¢‹ìŠµë‹ˆë‹¤.")