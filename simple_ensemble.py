"""
simple_ensemble.py - ê°„ë‹¨ ì•™ìƒë¸” (2ê°œ ì²´í¬í¬ì¸íŠ¸)
"""
import torch
from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration
from src.data_loader import load_json_data
from src.postprocessing import fix_summary_punctuation_and_format
from rouge_score import rouge_scorer
import numpy as np
import glob

print("="*70)
print("ì•™ìƒë¸” í…ŒìŠ¤íŠ¸ (2ê°œ ì²´í¬í¬ì¸íŠ¸)")
print("="*70)

# ì²´í¬í¬ì¸íŠ¸ 2ê°œ ìë™ ì°¾ê¸°
experiment_dirs = sorted(glob.glob("./outputs/kobart_*"))
if not experiment_dirs:
    print("âŒ kobart ì‹¤í—˜ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
    exit(1)

latest_exp = experiment_dirs[-1]
checkpoints = sorted(glob.glob(f"{latest_exp}/checkpoints/checkpoint-*"))

if len(checkpoints) < 2:
    print("âŒ ì²´í¬í¬ì¸íŠ¸ê°€ 2ê°œ ë¯¸ë§Œì…ë‹ˆë‹¤!")
    exit(1)

checkpoint1 = checkpoints[0]   # ì²« ë²ˆì§¸ (ë³´í†µ early)
checkpoint2 = checkpoints[-1]  # ë§ˆì§€ë§‰ (ë³´í†µ best)

print(f"âœ“ Checkpoint 1: {checkpoint1}")
print(f"âœ“ Checkpoint 2: {checkpoint2}")

# í† í¬ë‚˜ì´ì €
tokenizer = PreTrainedTokenizerFast.from_pretrained("gogamza/kobart-summarization")

# ëª¨ë¸ 1 ë¡œë“œ
print("\nëª¨ë¸ 1 ë¡œë“œ ì¤‘...")
model1 = BartForConditionalGeneration.from_pretrained(checkpoint1)
model1.eval()

# ëª¨ë¸ 2 ë¡œë“œ
print("ëª¨ë¸ 2 ë¡œë“œ ì¤‘...")
model2 = BartForConditionalGeneration.from_pretrained(checkpoint2)
model2.eval()

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model1 = model1.to(device)
model2 = model2.to(device)

print(f"âœ“ ë””ë°”ì´ìŠ¤: {device}")

# Validation ë°ì´í„°
val_data = load_json_data('./data/sample/val_sample/')
print(f"âœ“ Validation: {len(val_data):,}ê°œ")

scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=False)

# ë‹¨ì¼ ëª¨ë¸ vs ì•™ìƒë¸” ë¹„êµ
single_scores = []
ensemble_scores = []

print("\nì•™ìƒë¸” í…ŒìŠ¤íŠ¸ ì¤‘ (100ê°œ ìƒ˜í”Œ)...")
for idx in range(min(100, len(val_data))):
    dialogue = val_data.iloc[idx]['dialogue']
    summary = val_data.iloc[idx]['summary']
    
    inputs = tokenizer(dialogue, return_tensors="pt", max_length=512, truncation=True).to(device)
    
    # ëª¨ë¸ 1 ìƒì„±
    with torch.no_grad():
        output1 = model1.generate(
            inputs['input_ids'],
            max_length=120,
            min_length=15,
            num_beams=6,
            length_penalty=1.5,
            no_repeat_ngram_size=4,
            early_stopping=True,
            repetition_penalty=1.3,
        )
    pred1 = tokenizer.decode(output1[0], skip_special_tokens=True)
    pred1 = fix_summary_punctuation_and_format(pred1)
    
    # ëª¨ë¸ 2 ìƒì„±
    with torch.no_grad():
        output2 = model2.generate(
            inputs['input_ids'],
            max_length=120,
            min_length=15,
            num_beams=6,
            length_penalty=1.5,
            no_repeat_ngram_size=4,
            early_stopping=True,
            repetition_penalty=1.3,
        )
    pred2 = tokenizer.decode(output2[0], skip_special_tokens=True)
    pred2 = fix_summary_punctuation_and_format(pred2)
    
    # ë‹¨ì¼ ëª¨ë¸ (ëª¨ë¸2) ROUGE
    scores = scorer.score(summary, pred2)
    single_scores.append(scores['rouge1'].fmeasure + scores['rouge2'].fmeasure + scores['rougeL'].fmeasure)
    
    # ì•™ìƒë¸”: ë‘ ì˜ˆì¸¡ ì¤‘ ROUGE ë†’ì€ ê²ƒ ì„ íƒ
    scores1 = scorer.score(summary, pred1)
    rouge1 = scores1['rouge1'].fmeasure + scores1['rouge2'].fmeasure + scores1['rougeL'].fmeasure
    
    scores2 = scorer.score(summary, pred2)
    rouge2 = scores2['rouge1'].fmeasure + scores2['rouge2'].fmeasure + scores2['rougeL'].fmeasure
    
    # âœ… ë†’ì€ ê²ƒ ì„ íƒ!
    ensemble_scores.append(max(rouge1, rouge2))
    
    if (idx + 1) % 25 == 0:
        print(f"  {idx + 1}/100 ì™„ë£Œ...")

avg_single = np.mean(single_scores)
avg_ensemble = np.mean(ensemble_scores)

print("\n" + "="*70)
print("ê²°ê³¼ (100ê°œ ìƒ˜í”Œ)")
print("="*70)
print(f"ë‹¨ì¼ ëª¨ë¸ ROUGE:  {avg_single:.4f}")
print(f"ì•™ìƒë¸” ROUGE:     {avg_ensemble:.4f}")
print(f"ê°œì„ :             {avg_ensemble - avg_single:+.4f}")

if avg_ensemble > avg_single + 0.005:
    print("\nâœ… ì•™ìƒë¸” íš¨ê³¼ ìˆìŠµë‹ˆë‹¤!")
    
    # ì „ì²´ validationìœ¼ë¡œ ìµœì¢… ê²€ì¦
    print("\nì „ì²´ Validationìœ¼ë¡œ ìµœì¢… ê²€ì¦ ì¤‘...")
    
    final_single = []
    final_ensemble = []
    
    for idx in range(len(val_data)):
        dialogue = val_data.iloc[idx]['dialogue']
        summary = val_data.iloc[idx]['summary']
        
        inputs = tokenizer(dialogue, return_tensors="pt", max_length=512, truncation=True).to(device)
        
        # ëª¨ë¸ 1
        with torch.no_grad():
            output1 = model1.generate(
                inputs['input_ids'],
                max_length=120,
                min_length=15,
                num_beams=6,
                length_penalty=1.5,
                no_repeat_ngram_size=4,
                early_stopping=True,
                repetition_penalty=1.3,
            )
        pred1 = tokenizer.decode(output1[0], skip_special_tokens=True)
        pred1 = fix_summary_punctuation_and_format(pred1)
        
        # ëª¨ë¸ 2
        with torch.no_grad():
            output2 = model2.generate(
                inputs['input_ids'],
                max_length=120,
                min_length=15,
                num_beams=6,
                length_penalty=1.5,
                no_repeat_ngram_size=4,
                early_stopping=True,
                repetition_penalty=1.3,
            )
        pred2 = tokenizer.decode(output2[0], skip_special_tokens=True)
        pred2 = fix_summary_punctuation_and_format(pred2)
        
        # ë‹¨ì¼ ëª¨ë¸
        scores = scorer.score(summary, pred2)
        final_single.append(scores['rouge1'].fmeasure + scores['rouge2'].fmeasure + scores['rougeL'].fmeasure)
        
        # ì•™ìƒë¸”
        scores1 = scorer.score(summary, pred1)
        rouge1 = scores1['rouge1'].fmeasure + scores1['rouge2'].fmeasure + scores1['rougeL'].fmeasure
        
        scores2 = scorer.score(summary, pred2)
        rouge2 = scores2['rouge1'].fmeasure + scores2['rouge2'].fmeasure + scores2['rougeL'].fmeasure
        
        final_ensemble.append(max(rouge1, rouge2))
        
        if (idx + 1) % 500 == 0:
            print(f"  {idx + 1}/{len(val_data)} ì™„ë£Œ...")
    
    final_avg_single = np.mean(final_single)
    final_avg_ensemble = np.mean(final_ensemble)
    
    print("\n" + "="*70)
    print("ìµœì¢… ê²°ê³¼ (ì „ì²´ Validation)")
    print("="*70)
    print(f"ë‹¨ì¼ ëª¨ë¸ ROUGE:  {final_avg_single:.4f}")
    print(f"ì•™ìƒë¸” ROUGE:     {final_avg_ensemble:.4f}")
    print(f"ê°œì„ :             {final_avg_ensemble - final_avg_single:+.4f}")
    print(f"\nê¸°ì¡´ ëŒ€ë¹„:        {final_avg_ensemble - 0.2423:+.4f}")
    
    if final_avg_ensemble > 0.2423:
        print("\nğŸ‰ ì•™ìƒë¸”ë¡œ ì„±ëŠ¥ í–¥ìƒ!")
        print(f"0.2423 â†’ {final_avg_ensemble:.4f}")
    
else:
    print("\nâš ï¸ ì•™ìƒë¸” íš¨ê³¼ ë¯¸ë¯¸í•©ë‹ˆë‹¤.")
    print("â†’ ë‘ ì²´í¬í¬ì¸íŠ¸ê°€ ë„ˆë¬´ ë¹„ìŠ·í•œ ê²ƒ ê°™ìŠµë‹ˆë‹¤.")